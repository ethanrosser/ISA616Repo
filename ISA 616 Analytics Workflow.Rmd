---
title: "ISA 616 Analytics Workflow"
author: "Ethan Rosser"
date: "10/02/2020"
output: 
  html_document:
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Overview of Analysis

In this analysis, I create a regression model that uses physiochemical properties of wine to predict the wine quality score. This model will allow Winemakers at Wine Inc. to better understand what levels of physiochemical properties lead to a better wine quality score for their variants of the Portuguese “Vinho Verde” wine. This regression model will help Wine Inc. to produce higher quality wine, which in turn may help to increase sales revenue and brand reputation. This analysis may also help to decrease costs associated with creating new types of wine through trial and error because Winemakers within the company will have a statistically supported understanding of how each physiochemical property of the wine impacts the quality score. 

Below is the session information that was used to conduct this analysis, as well as the packages used. Be sure to have the correct version of R or packages installed or there may be issues with reproducibility.

```{r overview, results='hide'}
# Load in necessary packages
if (!require("pacman")) install.packages("pacman")
pacman::p_load(DataExplorer, corrplot, curl)
```

```{r sessionInfo}
sessionInfo()
```



# Data Description

I have accessed wine quality data from the University of California, Irvine’s Machine Learning Repository. There are two datasets related to red and white variants of the Portuguese “Vinho Verde” wine. One dataset is for the white variants, and one is for the red variants. We access these datasets directly via the curl package, but the link to manually download these two datasets is below just in case there are any issues:
https://archive.ics.uci.edu/ml/datasets/wine+quality

Before performing exploratory analysis, we first must combine the 2 datasets into 1. This is done by adding a "Color" variable on each dataset and then rbinding the datasets together. 

```{r combine, results='hide'}

# Read in 2 datasets. 1 dataset is for white wine and the other dataset is for red wine. 
white <- read.csv(curl("https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv"), sep = ";")

red <- read.csv(curl("https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv"), sep = ";")

# Create a column to specify the color of the wine for both datasets. 
white$Color <- "White"
red$Color <- "Red"

# Combine the red and white datasets together
wine <- white
wine <- rbind(wine, red)

# Change the data type for the Color variable to be a factor
wine$Color <- as.factor(wine$Color)

```

Now, we can properly describe the dataset. In our dataset, there are 6497 total observations and 13 variables. We have 12 numeric variables and 1 factor (Color) that has 2 categories: red and white.

```{r introduceData}
# Show the structure of the data set
str(wine)
```

This is the first 10 rows in the dataset to better show the structure of the data.
```{r}
head(wine)
```

This is the last 10 rows in the dataset to better show the structure of the data.
```{r}
tail(wine)
```

This bar chart shows the frequency of red and white wines within the data. There are 4898 observations of white wine and 1599 observations for red wine.

```{r barCharts}
# Plot bar charts to show the amount of data in each category for the categorical variables
plot_bar(wine)
```

These histograms show the distributions of values for each numeric variable within the dataset. Some of the variables have distributions that are skewed to the right, and this will be taken care of in pre-processing. 

```{r histograms}
# Plot histograms for the numeric variables
plot_histogram(wine)
```

There are 0 missing values in the dataset. This is a good thing because this cuts down considerably on the preprocessing work that needs to be done before modeling the data.

```{r missings}
# Plot the number of missing values for each variable
plot_missing(wine)
```

Here is a plot that shows the correlation between the numeric variables within the dataset. Overall, none of the variables have high enough of a correlation to be particularly concerning. But, we should make a note of the .72 correlation between total sulfur dioxide and free sulfur dioxide. Additionally, we should note the -.69 correlation between alcohol and density. But, neither of these correlations are high enough to suggest redunancy in the variables, so we will keep all of the predictors for modeling.  

```{r}
# Subset the data down to just the numeric variables
numericVars <- subset(wine, select = -c(Color))
# Create a correlation matrix
plot_correlation(numericVars, title = "Correlation Matrix")
```

# Preprocessing

The main preprocessing that needs to be done for this analysis is eliminating outliers from the numeric variables. 

```{r preprocessing}
# Remove the 2 outliers with very high chloride levels
wine <- wine[ which(wine$chlorides <= .4),]

# Remove the 2 outliers with very high citric acid levels
wine <- wine[ which(wine$citric.acid <= 1),]

# Remove the 1 outlier with a high density level
wine <- wine[ which(wine$density < 1.02),]

# Remove the 1 outlier with a very high free sulfur dioxide level that was over 100 points higher than the second highest value
wine <- wine[ which(wine$free.sulfur.dioxide <= 150),]

# Remove the 3 outliers with high sulphate levels
wine <- wine[ which(wine$sulphates <= 1.7),]

# Remove the 1 outlier with a high volatile acidity level
wine <- wine[ which(wine$volatile.acidity < 1.4),]

```

These are the resulting distributions of values for each variable after removing outliers. The distributions appear more normal and less skewed.

```{r histograms2}
# Plot histograms for the numeric variables
plot_histogram(wine)
```

# Modeling

```{r modeling}

# Split into training and testing datasets



null = lm(quality ~ 1, data = wine)
full = lm(quality ~ ., data = wine)

stepwise = step(null, scope = list(lower = null, upper = full), direction = "both", trace = 0, k = 2)

summary(stepwise)

```


# Conclusion

```{r}

```

